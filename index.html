<!doctype html>
<html>

<head>
<title>Xiaofan Li</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Xiaofan Li"> 
<meta name="description" content="Xiaofan Li's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />


</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Xiaofan Li 李晓帆<h1>
				</div>

		    
                <p>
		    I’m a graduate of Zhejiang University and currently a Technical Expert in the Autonomous Driving Foundation Model Department at Baidu. My work lies at the intersection of 3D computer vision, autonomous driving, and embodied intelligence, with a focus on open-set 3D perception and planning, vision-language models, implicit rendering and generation, and world models. 
			</br>
		</p>  
	        <p>
		    <b>Email</b>: shalfunnn@gmail.com </br>
		    [<a href="https://github.com/shalfun">Github</a>] [<a href="https://scholar.google.com/citations?user=pjZdkO4AAAAJ&hl=zh-CN">Google Scholar</a>] </br>
		</p>
		
			</td>

			</td>
			<td width="25%">
				<img src="assets/imgs/zhuye.jpg" width="100%"/>
			</td>
		<tr>
	</tbody>
</table>


<h2>News</h2>
<!-- <ul> -->
    [2024/07] DrivingDiffusion is accepted by ECCV 2024! </br>					
    [2023/03] ByteTrack ranks <a href="https://www.paperdigest.org/2023/01/most-influential-eccv-papers-2023-01/">1st of the most influential papers in ECCV 2022</a>! </br>
    [2022/07] Two papers accepted by ECCV 2022! </br>
    [2022/03] We are organizing <a href="https://motcomplex.github.io/">Multiple Object Tracking and Segmentation in Complex Environments Workshop</a>, ECCV 2022.
<!-- </ul> -->


<h2>Publications</h2>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/drivingdiffusion.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      DrivingDiffusion: Layout-Guided Multi-View Driving Scenarios Video Generation with Latent Diffusion Model
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      <b>lixiaofan</b>, Yifu Zhang, Xiaoqing Ye
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      European Conference on Computer Vision (<b>ECCV</b>), 2024
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/mpdrive.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      MPDrive: Improving Spatial Understanding with Marker-Based Prompt Learning for Autonomous Driving
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Zhiyuan Zhang*, <b>lixiaofan*</b>, Zhihao Xu, Wenjie Peng, Zijian Zhou, Miaojing Shi, Shuangping Huang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      Computer Vision and Pattern Recognition Conference (<b>CVPR</b>), 2025 <b>[Highlight]</b>
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/uvilar.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      U-ViLAR: Uncertainty-Aware Visual Localization for Autonomous Driving via Differentiable Association and Registration
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      <b>lixiaofan</b>, Zhihao Xu, Chenming Wu, Zhao Yang, Yumeng Zhang, Jiang-Jiang Liu, Haibao Yu, Xiaoqing Ye, YuAn Wang, Shirui Li, Xun Sun, Ji Wan, Jun Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      International Conference on Computer Vision (<b>ICCV</b>), 2025
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/dragyourgaussian.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation for 3D Gaussian Splatting
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Yansong Qu, Dian Chen, Xinyang Li, <b>lixiaofan</b>, Shengchuan Zhang, Liujuan Cao, Rongrong Ji
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      ACM SIGGRAPH Conference and Exhibition on Computer Graphics and Interactive Techniques (<b>SIGGRAPH</b>), 2025
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/driverse.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      DriVerse: Navigation World Model for Driving Simulation via Multimodal Trajectory Prompting and Motion Alignment
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      <b>lixiaofan</b>, Chenming Wu, Zhao Yang, Zhihao Xu, Dingkang Liang, Yumeng Zhang, Ji Wan, Jun Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2504.18576, 2025
      <p>[<a href="https://arxiv.org/abs/2504.18576" target="_blank" rel="noopener">paper</a>]</p>
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/dualdiffplus.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      DualDiff+: Dual-Branch Diffusion for High-Fidelity Video Generation with Reward Guidance
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Zhao Yang, Zezhong Qian, <b>lixiaofan</b>, Weixiang Xu, Gongpeng Zhao, Ruohong Yu, Lingsi Zhu, Longjun Liu
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2025
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/bevworld.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      BevWorld: A Multimodal World Model for Autonomous Driving via Unified BEV Latent Space
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Yumeng Zhang*, Shi Gong*, Kaixin Xiong*, Xiaoqing Ye, <b>lixiaofan</b>, Xiao Tan, Fan Wang, Jizhou Huang, Hua Wu, Haifeng Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2407.05679, 2024
      <p>[<a href="https://arxiv.org/abs/2407.05679" target="_blank" rel="noopener">paper</a>]</p>
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/worldmodelsurvey.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Sifan Tu, Xin Zhou, Dingkang Liang, Xingyu Jiang, Yumeng Zhang, <b>lixiaofan</b>, Xiang Bai
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2502.10498, 2025
      <p>[<a href="https://arxiv.org/abs/2502.10498" target="_blank" rel="noopener">paper</a>]</p>
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/cooptrack.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      CoopTrack: Exploring End-to-End Learning for Efficient Cooperative Sequential Perception
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Jiaru Zhong, Jiahao Wang, Jiahui Xu, <b>lixiaofan</b>, Zaiqing Nie, Haibao Yu
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      International Conference on Computer Vision (<b>ICCV</b>), 2025
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/descriptivecaption.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Descriptive Caption Enhancement with Visual Specialists for Multimodal Perception
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Yanpeng Sun, Jing Hao, Ke Zhu, Jiang-Jiang Liu, Yuxiang Zhao, <b>lixiaofan</b>, Gang Zhang, Zechao Li, Jingdong Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2412.14233, 2024
      <p>[<a href="https://arxiv.org/abs/2412.14233" target="_blank" rel="noopener">paper</a>]</p>
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/nerfdets.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      NeRF-DetS: Enhanced Adaptive Spatial-Wise Sampling and View-Wise Fusion Strategies for NeRF-Based Indoor Multi-View 3D Object Detection
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Chi Huang, Xinyang Li, Yansong Qu, Changli Wu, <b>lixiaofan</b>, Shengchuan Zhang, Liujuan Cao
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2024
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/mllmanalysis.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Revisiting MLLMs: An In-Depth Analysis of Image Classification Abilities
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Huan Liu, Lingyu Xiao, Jiangjiang Liu, <b>lixiaofan</b>, Ze Feng, Sen Yang, Jingdong Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2412.16418, 2024
      <p>[<a href="https://arxiv.org/abs/2412.16418" target="_blank" rel="noopener">paper</a>]</p>
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/learningmultipledecisions.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous Driving
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Lingyu Xiao, Jiang-Jiang Liu, Sen Yang, <b>lixiaofan</b>, Xiaoqing Ye, Wankou Yang, Jingdong Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2024
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/seeingthefuture.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Seeing the Future, Perceiving the Future: A Unified Driving World Model for Future Generation and Perception
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Dingkang Liang, Dingyuan Zhang, Xin Zhou, Sifan Tu, Tianrui Feng, <b>lixiaofan</b>, Yumeng Zhang, Mingyang Du, Xiao Tan, Xiang Bai
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2503.13587, 2025
      <p>[<a href="https://arxiv.org/abs/2503.13587" target="_blank" rel="noopener">paper</a>]</p>
  </div>
</div>
</br>

<h3>In Progress:</h3>

<div class="paper" style="clear:left;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/loopgen.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      LoopGen: Generative Street Scene Expansion via Diffusion-Aided Outlier Repair
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      <b>lixiaofan</b>, Yuan Wang, Ji Wan, Jun Wang
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Is Visual Language Model Good at Image Classification?
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Huan Liu, Lingyu Xiao, Jiang-Jiang Liu, <b>lixiaofan</b>, Ze Feng, Sen Yang
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      BUGS: Universal 3D Gaussian Splatting with a Bi-directional Gaussian Growing Mechanism
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Fan Duan, Yumeng Zhang, <b>lixiaofan</b>, Xiao Tan, Li Chen
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Vision Remember: Alleviating Visual Forgetting in Efficient MLLM with Vision Feature Resample
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Ze Feng, Jiang-Jiang Liu, Sen Yang, <b>lixiaofan</b>, Lingyu Xiao, Wankou Yang
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Rethinking Autonomous Driving Planner Beyond Tweaking the Framework
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Lingyu Xiao, Jiang-Jiang Liu, <b>lixiaofan</b>, Xiaoqing Ye, Wankou Yang
  </div>
</div>
</br>

<div class="paper" style="clear:left;">
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Controllable Panoramic Video Generation with 360-Degree Motion Consistency
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Yuzhi Chen, Qi Zeng, Muyang Zhang, Leilei Fan, <b>lixiaofan</b>, Changwei Wang, Rongtao Xu, Yanchao Liu, MingMing Yu, Weiliang Meng
  </div>
</div>
</br>



<h2>Academic Service</h2>

<ul>
    <li>
        Conference Reviewer: NeurIPS, ICLR, ICRA, IROS, CVPR, ICCV, ECCV, etc.
 </br>
    </li>

    <li>
        Journal Reviewer: IJCV, Pattern Recognition, Neurocomputing, TCSVT, NCAA</br> 
    </li>

</ul>

<table width="100%"> 
	<tr> 
		<td align="center">&copy; Xiaofan Li | Last update: June 2025</td>
	</tr> 
</table>

</div>


</body>

</html>
