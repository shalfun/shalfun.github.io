<!doctype html>
<html>

<head>
<title>Xiaofan Li</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Xiaofan Li"> 
<meta name="description" content="Xiaofan Li's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />


</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
  <td width="75%" style="padding-right: 20px;">
    <div id="toptitle">
      <h1>Xiaofan Li</h1>
    </div>

    <p>
      I obtained my Bachelor's degree from Zhejiang University (ZJU), where I conducted research under the supervision of Professors Kaiwei Wang, Guofeng Zhang, and Zhihai Xu. 
    I previously joined the Autonomous Driving Foundation Model Department at Baidu as a Technical Expert, where I worked on 3D perception, vision-language models, implicit rendering and generation, and world models. I am currently working at X Square Robot, continuing to explore research at the intersection of 3D computer vision, autonomous driving, and embodied intelligence.
My research has been centered on open-set 3D spatial perception and planning, as well as unified multimodal models for understanding, perception, planning, and generation.
      <br/>
    </p>  
    <p>
      <b>Email</b>: shalfunnn@gmail.com <br/>
      [<a href="https://github.com/shalfun">Github</a>] [<a href="https://scholar.google.com/citations?user=pjZdkO4AAAAJ&hl=zh-CN">Google Scholar</a>] <br/>
    </p>
  </td>

  <td width="25%">
    <img src="assets/imgs/me.png" width="100%"/>
  </td>
</tr>


	</tbody>
</table>


<h2>News</h2>
<!-- <ul> -->
    [2025/07] Drivers accepted by ACMMM 2025! </br>					
    [2025/06] Two papers accepted by ICCV 2025! </br>
    [2025/04] MPDrive accepted by CVPR 2025 as a Highlight! </br>
    [2025/03] Drag-Your-Gaussian accepted by SIGGRAPH 2025! </br>	
    [2025/02] Two papers accepted by IJCAI 2025! </br>
    [2025/02] Two papers accepted by ICRA 2025! </br>	
    [2024/07] DrivingDiffusion is accepted by ECCV 2024! </br>	
<!--     [2023/01] DrivingDiffusion is Done! </br>					 -->

<!-- </ul> -->


<h2>Publications</h2>

<!-- <div class="paper" style="clear:left; margin-bottom:30px;"> -->
<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/drivingdiffusion.jpg" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      DrivingDiffusion: Layout-Guided Multi-View Driving Scenarios Video Generation with Latent Diffusion Model
      [<a href="https://arxiv.org/abs/2310.07771" target="_blank" rel="noopener">paper</a>]
      [<a href="https://github.com/shalfun/DrivingDiffusion" target="_blank" rel="noopener">code</a>]
      
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      <b>Xiaofan Li</b>, Yifu Zhang, Xiaoqing Ye
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      European Conference on Computer Vision (<b>ECCV</b>), 2024
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/mpdrive.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      MPDrive: Improving Spatial Understanding with Marker-Based Prompt Learning for Autonomous Driving
      	[<a href="https://arxiv.org/pdf/2504.00379" target="_blank" rel="noopener">paper</a>]
<!--       	[<a href="https://github.com/shalfun/DrivingDiffusion" target="_blank" rel="noopener">code</a>] -->
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Zhiyuan Zhang*, <b>Xiaofan Li*</b>, Zhihao Xu, Wenjie Peng, Zijian Zhou, Miaojing Shi, Shuangping Huang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      Computer Vision and Pattern Recognition Conference (<b>CVPR</b>), 2025 <b>[Highlight]</b>
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/uvilar.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      U-ViLAR: Uncertainty-Aware Visual Localization for Autonomous Driving via Differentiable Association and Registration
      	[<a href="https://www.arxiv.org/abs/2507.04503" target="_blank" rel="noopener">paper</a>]
<!--       	[<a href="https://github.com/shalfun/DrivingDiffusion" target="_blank" rel="noopener">code</a>] -->
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      <b>Xiaofan Li</b>, Zhihao Xu, Chenming Wu, Zhao Yang, Yumeng Zhang, Jiang-Jiang Liu, Haibao Yu, Xiaoqing Ye, YuAn Wang, Shirui Li, Xun Sun, Ji Wan, Jun Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      International Conference on Computer Vision (<b>ICCV</b>), 2025
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/drag.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation for 3D Gaussian Splatting
      	[<a href="https://arxiv.org/pdf/2501.18672" target="_blank" rel="noopener">paper</a>]
      	[<a href="https://github.com/Quyans/Drag-Your-Gaussian" target="_blank" rel="noopener">code</a>]
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Yansong Qu, Dian Chen, Xinyang Li, <b>Xiaofan Li</b>, Shengchuan Zhang, Liujuan Cao, Rongrong Ji
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      ACM SIGGRAPH Conference and Exhibition on Computer Graphics and Interactive Techniques (<b>SIGGRAPH</b>), 2025
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/driverse.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      DriVerse: Navigation World Model for Driving Simulation via Multimodal Trajectory Prompting and Motion Alignment
      	[<a href="https://arxiv.org/pdf/2504.18576" target="_blank" rel="noopener">paper</a>]
      	[<a href="https://github.com/shalfun/DriVerse" target="_blank" rel="noopener">code</a>]
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      <b>Xiaofan Li</b>, Chenming Wu, Zhao Yang, Zhihao Xu, Dingkang Liang, Yumeng Zhang, Ji Wan, Jun Wang
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/dualdiff.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      DualDiff+: Dual-Branch Diffusion for High-Fidelity Video Generation with Reward Guidance
      	[<a href="https://arxiv.org/pdf/2503.03689" target="_blank" rel="noopener">paper</a>]
      	[<a href="https://github.com/yangzhaojason/DualDiff" target="_blank" rel="noopener">code</a>]
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Zhao Yang, Zezhong Qian, <b>Xiaofan Li</b>, Weixiang Xu, Gongpeng Zhao, Ruohong Yu, Lingsi Zhu, Longjun Liu
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2025
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/bevworld.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      BevWorld: A Multimodal World Model for Autonomous Driving via Unified BEV Latent Space
      	[<a href="https://arxiv.org/abs/2407.05679" target="_blank" rel="noopener">paper</a>]
      	[<a href="https://github.com/shalfun/BevWorld" target="_blank" rel="noopener">code</a>]
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Yumeng Zhang*, Shi Gong*, Kaixin Xiong*, Xiaoqing Ye, <b>Xiaofan Li</b>, Xiao Tan, Fan Wang, Jizhou Huang, Hua Wu, Haifeng Wang
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/wmsurvey.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey
      	[<a href="https://arxiv.org/pdf/2502.10498" target="_blank" rel="noopener">paper</a>]
      	[<a href="https://github.com/LMD0311/Awesome-World-Model" target="_blank" rel="noopener">code</a>](1.2k)
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Sifan Tu, Xin Zhou, Dingkang Liang, Xingyu Jiang, Yumeng Zhang, <b>Xiaofan Li</b>, Xiang Bai
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/cooptrack.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      CoopTrack: Exploring End-to-End Learning for Efficient Cooperative Sequential Perception
<!--       	[<a href="https://arxiv.org/abs/2310.07771" target="_blank" rel="noopener">paper</a>]
      	[<a href="https://github.com/shalfun/DrivingDiffusion" target="_blank" rel="noopener">code</a>] -->
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Jiaru Zhong, Jiahao Wang, Jiahui Xu, <b>Xiaofan Li</b>, Zaiqing Nie, Haibao Yu
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      International Conference on Computer Vision (<b>ICCV</b>), 2025
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/des.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Descriptive Caption Enhancement with Visual Specialists for Multimodal Perception
      	[<a href="https://arxiv.org/pdf/2412.14233" target="_blank" rel="noopener">paper</a>]
<!--       	[<a href="https://github.com/shalfun/DrivingDiffusion" target="_blank" rel="noopener">code</a>] -->
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Yanpeng Sun, Jing Hao, Ke Zhu, Jiang-Jiang Liu, Yuxiang Zhao, <b>Xiaofan Li</b>, Gang Zhang, Zechao Li, Jingdong Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2412.14233, 2024
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/nerfdets.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      NeRF-DetS: Enhanced Adaptive Spatial-Wise Sampling and View-Wise Fusion Strategies for NeRF-Based Indoor Multi-View 3D Object Detection
      	[<a href="https://arxiv.org/pdf/2404.13921" target="_blank" rel="noopener">paper</a>]
<!--       	[<a href="https://github.com/shalfun/DrivingDiffusion" target="_blank" rel="noopener">code</a>] -->
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Chi Huang, Xinyang Li, Yansong Qu, Changli Wu, <b>Xiaofan Li</b>, Shengchuan Zhang, Liujuan Cao
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2024
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/mllmanalysis.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Revisiting MLLMs: An In-Depth Analysis of Image Classification Abilities
      	[<a href="https://arxiv.org/pdf/2412.16418" target="_blank" rel="noopener">paper</a>]
<!--       	[<a href="https://github.com/shalfun/DrivingDiffusion" target="_blank" rel="noopener">code</a>] -->
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Huan Liu, Lingyu Xiao, Jiangjiang Liu, <b>Xiaofan Li</b>, Ze Feng, Sen Yang, Jingdong Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2412.16418, 2024
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/Learning.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous Driving
      	[<a href="https://arxiv.org/pdf/2409.15730" target="_blank" rel="noopener">paper</a>]
      	[<a href="https://github.com/syp2ysy/EDC" target="_blank" rel="noopener">code</a>]
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Lingyu Xiao, Jiang-Jiang Liu, Sen Yang, <b>Xiaofan Li</b>, Xiaoqing Ye, Wankou Yang, Jingdong Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2024
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/seeing.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Seeing the Future, Perceiving the Future: A Unified Driving World Model for Future Generation and Perception
      	[<a href="https://arxiv.org/pdf/2503.13587" target="_blank" rel="noopener">paper</a>]
      	[<a href="https://github.com/dk-liang/UniFuture" target="_blank" rel="noopener">code</a>]
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Dingkang Liang, Dingyuan Zhang, Xin Zhou, Sifan Tu, Tianrui Feng, <b>Xiaofan Li</b>, Yumeng Zhang, Mingyang Du, Xiao Tan, Xiang Bai
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2503.13587, 2025
  </div>
</div>
</br>


<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/vremenber.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Vision Remember: Alleviating Visual Forgetting in Efficient MLLM with Vision Feature Resample
      	[<a href="https://arxiv.org/pdf/2506.03928" target="_blank" rel="noopener">paper</a>]
<!--       	[<a href="https://github.com/dk-liang/UniFuture" target="_blank" rel="noopener">code</a>] -->
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Ze Feng, Jiang-Jiang Liu, Sen Yang, Lingyu Xiao, Xiaofan Li, Wankou Yang, Jingdong Wang
  </div>
  <div class="pvenue" style="padding:1px;margin-left:215px;">
      arXiv preprint arXiv:2506.03928, 2025
  </div>
</div>
</br>

						
<h3>In Progress:</h3>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/loop.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      LoopGen: Generative Street Scene Expansion via Diffusion-Aided Outlier Repair
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      <b>Xiaofan Li</b>, Yuan Wang, Ji Wan, Jun Wang
  </div>
</div>
</br>


						
<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/bugs.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      BUGS: Universal 3D Gaussian Splatting with a Bi-directional Gaussian Growing Mechanism
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Fan Duan, Yumeng Zhang, <b>Xiaofan Li</b>, Xiao Tan, Li Chen
  </div>
</div>
</br>


<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/read.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Rethinking Autonomous Driving Planner Beyond Tweaking the Framework
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Lingyu Xiao, Jiang-Jiang Liu, <b>Xiaofan Li</b>, Xiaoqing Ye, Wankou Yang
  </div>
</div>
</br>

<div class="paper" style="clear:left; margin-bottom:30px;">
  <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
      <img src="assets/imgs/yz.png" width="200" >
  </div>
  <div class="ptitle" style="padding:1px;margin-left:215px;">
      Controllable Panoramic Video Generation with 360-Degree Motion Consistency
  </div>
  <div class="pauthors" style="padding:1px;margin-left:215px;">
      Yuzhi Chen, Qi Zeng, Muyang Zhang, Leilei Fan, <b>Xiaofan Li</b>, Changwei Wang, Rongtao Xu, Yanchao Liu, MingMing Yu, Weiliang Meng
  </div>
</div>
</br>



<h2>Academic Service</h2>

<ul>
    <li>
        Conference Reviewer: NeurIPS, ICLR, ICRA, IROS, CVPR, ICCV, ECCV, etc.
 </br>
    </li>

    <li>
        Journal Reviewer: IJCV, Pattern Recognition, Neurocomputing, TCSVT, NCAA</br> 
    </li>

</ul>

<table width="100%"> 
	<tr> 
		<td align="center">&copy; Xiaofan Li | Last update: June 2025</td>
	</tr> 
</table>

</div>


</body>

</html>
